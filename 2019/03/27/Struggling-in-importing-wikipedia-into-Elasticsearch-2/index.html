<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fuzihaofzh.github.io","root":"/blog/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="By Z.H. Fu https:&#x2F;&#x2F;fuzihaofzh.github.io&#x2F;blog&#x2F; We have introduced many tools and tricks in my previous post Struggling in importing wikipedia into Elasticsearch. In that post, we successfully import Wi">
<meta property="og:type" content="article">
<meta property="og:title" content="Struggling in importing wikipedia into Elasticsearch (2)">
<meta property="og:url" content="http://fuzihaofzh.github.io/blog/2019/03/27/Struggling-in-importing-wikipedia-into-Elasticsearch-2/index.html">
<meta property="og:site_name" content="切问录">
<meta property="og:description" content="By Z.H. Fu https:&#x2F;&#x2F;fuzihaofzh.github.io&#x2F;blog&#x2F; We have introduced many tools and tricks in my previous post Struggling in importing wikipedia into Elasticsearch. In that post, we successfully import Wi">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-03-27T15:03:18.000Z">
<meta property="article:modified_time" content="2023-09-03T22:16:27.668Z">
<meta property="article:author" content="Z.H. Fu">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://fuzihaofzh.github.io/blog/2019/03/27/Struggling-in-importing-wikipedia-into-Elasticsearch-2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Struggling in importing wikipedia into Elasticsearch (2) | 切问录</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">切问录</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/blog/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://fuzihaofzh.github.io/blog/2019/03/27/Struggling-in-importing-wikipedia-into-Elasticsearch-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/lion.png">
      <meta itemprop="name" content="Z.H. Fu">
      <meta itemprop="description" content="Z.H. Fu的博客，主要关注数学、力学、计算机相关内容">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="切问录">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Struggling in importing wikipedia into Elasticsearch (2)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-03-27 15:03:18" itemprop="dateCreated datePublished" datetime="2019-03-27T15:03:18+00:00">2019-03-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-09-03 23:16:27" itemprop="dateModified" datetime="2023-09-03T23:16:27+01:00">2023-09-03</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/blog/2019/03/27/Struggling-in-importing-wikipedia-into-Elasticsearch-2/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/03/27/Struggling-in-importing-wikipedia-into-Elasticsearch-2/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>581</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>2 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <center>By Z.H. Fu</center>
<center><a href="https://fuzihaofzh.github.io/blog/">https://fuzihaofzh.github.io/blog/</a></center>
<p>We have introduced many tools and tricks in my previous post Struggling in importing wikipedia into Elasticsearch. In that post, we successfully import Wikipedia into elasticsearch with logstash. However, things are not settled. The biggest problem of logstash is that it’s extremely user-unfriendly. Even filter an html tag will waste you half days searching google how to do modify the config file. It made very annoy sine I totally forget all the tricks of logstash. Therefore, we will explore how to use python to import the Wikipedia into elasticsearch directly.</p>
<p>The first step is to convert the Wikipedia source file into a more formatted one. I choose to use <a target="_blank" rel="noopener" href="https://radimrehurek.com/gensim/scripts/segment_wiki.html">gensim</a>’s Wikipedia tool to do this. It can be run like this:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m gensim.scripts.segment_wiki -i -f enwiki-20190320-pages-articles-multistream.xml.bz2 -o enwiki-20190320-pages-articles-multistream.json.gz -w 100</span><br></pre></td></tr></table></figure>
<p>It will convert the latest <span id="more"></span> Wikipedia dump to a .json.gz file, in which each contains a JSON dict representation a page. The detail can be obtained from the official sites of gensim.</p>
<p>Afterwards, we get a well-formated file enwiki-20190320-pages-articles-multistream.json.gz . We will then import this line by line into elasticsearch.</p>
<p>Before we begin to write our code. We should firstly set some parameters for elasticsearch to make it more capable to hold large data and query. There are two modifications:</p>
<ul>
<li>in <code>config/elasticsearch.yml</code>, add:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">thread_pool:</span><br><span class="line">  bulk:</span><br><span class="line">    size: 32</span><br><span class="line">    queue_size: 50000</span><br></pre></td></tr></table></figure>
<p>This will make the thread pool much larger than the default one. It makes elasticsearch capable to handle multiple queries.</p>
<ul>
<li>config/jvm.options:<br />
change <code>-Xmx1g</code> to <code>-Xmx32g</code> to make it have a larger jvm heap size. If the jvm heap size is not large enough, the elasticsearch will throw errors.</li>
</ul>
<p>Finally, we can read from the new Wikipedia data file and import into elasticsearch, the script is as follows:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process,Queue, Pool</span><br><span class="line">import bz2, sys</span><br><span class="line">import xmltodict</span><br><span class="line">from tqdm.auto import tqdm</span><br><span class="line">from elasticsearch import Elasticsearch</span><br><span class="line">from elasticsearch import helpers</span><br><span class="line">from multiprocessing import Pool</span><br><span class="line">import io, os</span><br><span class="line">import json</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">consumer_n = 20</span><br><span class="line">buck_size = 40</span><br><span class="line">wiki = &quot;../enwiki-20190320-pages-articles-multistream.json.gz&quot;</span><br><span class="line">totoal_num = 5226713#60283085#30302#60283085</span><br><span class="line"></span><br><span class="line">def import_es(es, lines):</span><br><span class="line">    pages = []</span><br><span class="line">    for line in lines:</span><br><span class="line">        page = json.loads(line)</span><br><span class="line">        for key in page.keys():</span><br><span class="line">            page[key] = json.dumps(page[key])</span><br><span class="line">        if &#x27;interlinks&#x27; in page:</span><br><span class="line">            page[&#x27;entitylinks&#x27;] = page.pop(&#x27;interlinks&#x27;)</span><br><span class="line">        page[&#x27;_index&#x27;] = &#x27;enwiki_20190320&#x27;</span><br><span class="line">        page[&#x27;_type&#x27;] = &quot;wiki&quot;</span><br><span class="line">        pages.append(page)</span><br><span class="line">    res = helpers.bulk(es, pages)</span><br><span class="line">    #res = es.index(index=, doc_type = &quot;wiki&quot;, body=page)</span><br><span class="line"></span><br><span class="line">pbar = tqdm(total=totoal_num)</span><br><span class="line"></span><br><span class="line">def procducer(q, wikifile, pbar):</span><br><span class="line">    begin_record = False</span><br><span class="line">    cnt = 0</span><br><span class="line">    print(&quot;processing...&quot;)</span><br><span class="line">    for line in os.popen(&quot;zcat %s&quot;%wikifile):</span><br><span class="line">        pbar.update(max(cnt - q.qsize() - pbar.n, 0))</span><br><span class="line">        q.put(line)</span><br><span class="line">        cnt += 1</span><br><span class="line">        pbar.set_description(&quot;Queue Remain: %s&quot; % q.qsize())</span><br><span class="line">    print(&quot;total pages: %d&quot;, cnt)</span><br><span class="line"></span><br><span class="line">    for i in range(consumer_n):</span><br><span class="line">        q.put(None)</span><br><span class="line">    while q.qsize() &gt; 0:</span><br><span class="line">        time.sleep(1)</span><br><span class="line">        pbar.update(max(cnt - q.qsize() - pbar.n, 0))</span><br><span class="line">        pbar.set_description(&quot;Queue Remain: %s&quot; % q.qsize())</span><br><span class="line">    print(&quot;End procducer&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def consumer(q):</span><br><span class="line">    es=Elasticsearch([&#123;&#x27;host&#x27;:&#x27;localhost&#x27;,&#x27;port&#x27;:9200&#125;], timeout=50, max_retries=10, retry_on_timeout=True)</span><br><span class="line">    pages = []</span><br><span class="line">    while True:</span><br><span class="line">        res=q.get()</span><br><span class="line">        if res == None or len(pages) &gt;= buck_size:</span><br><span class="line">            import_es(es, pages)</span><br><span class="line">            pages = []</span><br><span class="line">        if res is None:</span><br><span class="line">            break</span><br><span class="line">        pages.append(res)</span><br><span class="line"></span><br><span class="line">    print(&quot;End consumer&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    q=Queue()</span><br><span class="line">    p=Process(target=procducer,args=(q, wiki, pbar))</span><br><span class="line">    p.start()</span><br><span class="line"></span><br><span class="line">    cs = []</span><br><span class="line">    for _ in range(consumer_n):</span><br><span class="line">        c = Process(target=consumer,args=(q,))</span><br><span class="line">        c.start()</span><br><span class="line">        cs.append(c)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    p.join()</span><br><span class="line"></span><br><span class="line">    for c in cs:</span><br><span class="line">        c.join()</span><br><span class="line">    pbar.close()</span><br><span class="line"></span><br><span class="line">    print(&#x27;Finish Processing.&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>In this script, we use a producer-consumer model to read and import the data into elasticsearch.</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2018/07/28/%E6%95%B4%E6%95%B0%E8%A7%84%E5%88%92%E5%BB%BA%E6%A8%A1%E6%8A%80%E5%B7%A7/" rel="prev" title="整数规划建模技巧">
      <i class="fa fa-chevron-left"></i> 整数规划建模技巧
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2019/09/07/Install-Ubuntu-on-QEMU/" rel="next" title="Install Ubuntu on QEMU">
      Install Ubuntu on QEMU <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Z.H. Fu"
      src="/blog/images/lion.png">
  <p class="site-author-name" itemprop="name">Z.H. Fu</p>
  <div class="site-description" itemprop="description">Z.H. Fu的博客，主要关注数学、力学、计算机相关内容</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">76</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
          
        <span class="site-state-item-count">57</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Z.H. Fu</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">138k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">8:20</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>




  




  
<script src="/blog/js/local-search.js"></script>













  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://maplewizard.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "http://fuzihaofzh.github.io/blog/2019/03/27/Struggling-in-importing-wikipedia-into-Elasticsearch-2/";
    this.page.identifier = "2019/03/27/Struggling-in-importing-wikipedia-into-Elasticsearch-2/";
    this.page.title = "Struggling in importing wikipedia into Elasticsearch (2)";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://maplewizard.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
