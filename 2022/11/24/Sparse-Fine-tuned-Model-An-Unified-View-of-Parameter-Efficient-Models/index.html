<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"fuzihaofzh.github.io","root":"/blog/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="By Z.H. Fu https:&#x2F;&#x2F;fuzihaofzh.github.io&#x2F;blog&#x2F; In the realm of machine learning, fine-tuning pre-trained models is a common practice. However, it often requires a significant amount of parameters and c">
<meta property="og:type" content="article">
<meta property="og:title" content="Sparse Fine-tuned Model -- An Unified View of Parameter-Efficient Models">
<meta property="og:url" content="http://fuzihaofzh.github.io/blog/2022/11/24/Sparse-Fine-tuned-Model-An-Unified-View-of-Parameter-Efficient-Models/index.html">
<meta property="og:site_name" content="切问录">
<meta property="og:description" content="By Z.H. Fu https:&#x2F;&#x2F;fuzihaofzh.github.io&#x2F;blog&#x2F; In the realm of machine learning, fine-tuning pre-trained models is a common practice. However, it often requires a significant amount of parameters and c">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://fuzihaofzh.github.io/blog/images/adapterandlora.png">
<meta property="article:published_time" content="2022-11-24T10:40:48.000Z">
<meta property="article:modified_time" content="2023-09-04T10:11:22.116Z">
<meta property="article:author" content="Z.H. Fu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://fuzihaofzh.github.io/blog/images/adapterandlora.png">

<link rel="canonical" href="http://fuzihaofzh.github.io/blog/2022/11/24/Sparse-Fine-tuned-Model-An-Unified-View-of-Parameter-Efficient-Models/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Sparse Fine-tuned Model -- An Unified View of Parameter-Efficient Models | 切问录</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">切问录</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/blog/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://fuzihaofzh.github.io/blog/2022/11/24/Sparse-Fine-tuned-Model-An-Unified-View-of-Parameter-Efficient-Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/lion.png">
      <meta itemprop="name" content="Z.H. Fu">
      <meta itemprop="description" content="Z.H. Fu的博客，主要关注数学、力学、计算机相关内容">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="切问录">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Sparse Fine-tuned Model -- An Unified View of Parameter-Efficient Models
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-11-24 10:40:48" itemprop="dateCreated datePublished" datetime="2022-11-24T10:40:48+00:00">2022-11-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-09-04 11:11:22" itemprop="dateModified" datetime="2023-09-04T11:11:22+01:00">2023-09-04</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/blog/2022/11/24/Sparse-Fine-tuned-Model-An-Unified-View-of-Parameter-Efficient-Models/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2022/11/24/Sparse-Fine-tuned-Model-An-Unified-View-of-Parameter-Efficient-Models/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>1.2k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>4 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <center>By Z.H. Fu</center>
<center><a href="https://fuzihaofzh.github.io/blog/">https://fuzihaofzh.github.io/blog/</a></center>
<p>In the realm of machine learning, fine-tuning pre-trained models is a common practice. However, it often requires a significant amount of parameters and computational resources. To address this, researchers have proposed various parameter-efficient models, each with their own unique approach to fine-tuning. In this blog post, we will be discussing a unified view of these models, focusing on how they align with the definition of a sparse fine-tuned model. This view is a brief explanation of the study “<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2211.15583.pdf">On the effectiveness of parameter-efficient fine-tuning</a>” by Zihao Fu et al. <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>, can provide a unified understanding of parameter-efficient models and can be instrumental in further analysis and research. <span id="more"></span></p>
<h2 id="what-is-a-sparse-fine-tuned-model"><a class="markdownIt-Anchor" href="#what-is-a-sparse-fine-tuned-model"></a> What is a Sparse Fine-tuned Model?</h2>
<p>A sparse fine-tuned model refers to a fine-tuned model that shares the same structure as the pre-trained model, with a certain level of sparsity in the difference of their parameters. More formally, it is defined as follows:</p>
<blockquote>
<p><strong>Definition(Sparse Fine-tuned Model)</strong> given a pre-trained model <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>M</mi><mn>0</mn></msup></mrow><annotation encoding="application/x-tex">M^0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span> with parameters <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>θ</mi><mn>0</mn></msup></mrow><annotation encoding="application/x-tex">\theta^0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span>, if a fine-tuned model <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> with parameters <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> shares the same structure as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>M</mi><mn>0</mn></msup></mrow><annotation encoding="application/x-tex">M^0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span> such that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∥</mi><mi>θ</mi><mo>−</mo><msup><mi>θ</mi><mn>0</mn></msup><msub><mi mathvariant="normal">∥</mi><mn>0</mn></msub><mo>≤</mo><mi>p</mi><mi>dim</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>p</mi><mo>∈</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\|\theta-\theta^0\|_0\le p\dim(\theta),p\in(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∥</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">dim</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>, we say the model <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> is a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>-sparse fine-tuned model with the sparsity <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span>.</p>
</blockquote>
<p>This concept of sparsity is used to represent the degree of change between the pre-trained model and the fine-tuned model. A sparser model indicates a smaller degree of change, which can lead to more efficient usage of parameters.</p>
<h2 id="parameter-efficient-fine-tuning-models"><a class="markdownIt-Anchor" href="#parameter-efficient-fine-tuning-models"></a> Parameter-Efficient Fine-tuning Models</h2>
<p>This paper <sup class="footnote-ref"><a href="#fn1" id="fnref1:1">[1:1]</a></sup> have categorized parameter-efficient fine-tuning models into three main categories: random approaches, rule-based approaches, and projection-based approaches. Each of these categories has a unique approach towards parameter selection, but all of them ultimately align with the definition of a sparse fine-tuned model. Let’s dive into each of these categories.</p>
<h3 id="random-approaches"><a class="markdownIt-Anchor" href="#random-approaches"></a> Random Approaches</h3>
<p>Models in this category, such as <strong>Random</strong> and <strong>Mixout</strong>, randomly select parameters to be fine-tuned.</p>
<p>The <strong>Random</strong> model is straightforward - it selects parameters randomly with respect to a given sparsity ratio and then trains the selected parameters. As the selection does not depend on any specific data or rules, it complies with the definition of a sparse fine-tuned model.</p>
<p>The <strong>Mixout</strong> <sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> model , on the other hand, proposes to directly reset a portion of the fine-tuned model’s parameters to the pre-trained parameters with respect to a ratio. This approach also aligns with the definition of a sparse fine-tuned model as it maintains a certain level of sparsity in the parameter changes.</p>
<h3 id="rule-based-approaches"><a class="markdownIt-Anchor" href="#rule-based-approaches"></a> Rule-Based Approaches</h3>
<p>Rule-based approaches, such as <strong>BitFit</strong>, <strong>MagPruning</strong>, <strong>Adapter</strong>, and <strong>LoRA</strong>, use predefined rules to select parameters for fine-tuning.</p>
<p>The <strong>BitFit</strong> <sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> model is a prime example of a rule-based approach. It only fine-tunes the bias-terms and achieves considerably good performance. This approach of pre-defining the weights to be tuned aligns with the definition of a sparse fine-tuned model.</p>
<p>The <strong>MagPruning</strong> <sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> model follows the idea that large weights are more important in the model. It ranks the weights by the absolute value and tunes the parameters with high absolute values. This model also complies with the definition of a sparse fine-tuned model as it maintains a certain level of sparsity in the parameter changes.</p>
<p>The <strong>Adapter</strong> <sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup> model proposes to add an adapter layer inside the transformer layer. While this alters the original model’s structure, the Adapter model can be viewed as fine-tuning an equivalent model which initializes the matrix <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal">A</span></span></span></span> as an all-zero matrix. This equivalent model has the same output as the original pre-trained model for any input, while the structure is the same as the Adapter model. Therefore, fine-tuning the Adapter model can be viewed as fine-tuning partial parameters of the equivalent model with the same structure, making it a sparse fine-tuned model with respect to the equivalent model.</p>
<p>The <strong>LoRA</strong> <sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup> model proposes to add a new vector calculated by recovering a hidden vector from a lower dimension space. The original initialization makes the LoRA model an equivalent model for the original pre-trained model as the matrix <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> is set to 0. Therefore, fine-tuning a LoRA model can also be viewed as fine-tuning partial parameters of the equivalent model with the same structure, making it a sparse fine-tuned model as well.</p>
<p><img src="/blog/images/adapterandlora.png" alt="adapterandlora" /></p>
<h3 id="projection-based-approaches"><a class="markdownIt-Anchor" href="#projection-based-approaches"></a> Projection-Based Approaches</h3>
<p>Projection-based approaches, such as <strong>DiffPruning</strong> and <strong>ChildPruning</strong>, utilize task-specific data to select tunable parameters.</p>
<p>The <strong>DiffPruning</strong> <sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup> model proposes to model the parameter selection mask as a Bernoulli random variable and optimize the variable with a reparametrization method. It then projects the mask onto <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span>’s feasible region and performs the optimization alternately. Therefore, it also aligns with the definition of a sparse fine-tuned model.</p>
<p>The <strong>ChildPruning</strong> <sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup> model proposes to iteratively train the full model parameters and then calculates the projected mask to find the child network. This approach of alternating between full model training and mask projection also complies with the definition of a sparse fine-tuned model.</p>
<h2 id="in-conclusion"><a class="markdownIt-Anchor" href="#in-conclusion"></a> In Conclusion</h2>
<p>The sparse fine-tuned model provides a unified view of various parameter-efficient models. By adhering to the definition of a sparse fine-tuned model, these models can achieve efficient usage of parameters during fine-tuning, leading to more effective and resource-friendly machine learning models. For a more comprehensive understanding of this concept, kindly refer to the original paper, <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2211.15583.pdf">On the effectiveness of parameter-efficient fine-tuning</a><sup class="footnote-ref"><a href="#fn1" id="fnref1:2">[1:2]</a></sup>, or visit the corresponding <a target="_blank" rel="noopener" href="https://github.com/fuzihaofzh/AnalyzeParameterEfficientFinetune">Github Homepage</a>.</p>
<hr class="footnotes-sep" />
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>Fu, Z., Yang, H., So, A. M., Lam, W., Bing, L., &amp; Collier, N. (2023). <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2211.15583.pdf">On the effectiveness of parameter-efficient fine-tuning</a>. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 37, No. 11, pp. 12799-12807). <a href="#fnref1" class="footnote-backref">↩︎</a> <a href="#fnref1:1" class="footnote-backref">↩︎</a> <a href="#fnref1:2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn2" class="footnote-item"><p>Lee, C., Cho, K., &amp; Kang, W. (2019). Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models. In International Conference on Learning Representations. <a href="#fnref2" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn3" class="footnote-item"><p>Zaken, E. B., Ravfogel, S., &amp; Goldberg, Y. (2021). Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models. arXiv preprint arXiv:2106.10199. <a href="#fnref3" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn4" class="footnote-item"><p>Han, S., Mao, H., &amp; Dally, W. J. (2015). Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149. <a href="#fnref4" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn5" class="footnote-item"><p>Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Gesmundo, A., Attariyan, M., &amp; Gelly, S. (2019). Parameter-efficient transfer learning for NLP. In International Conference on Machine Learning (pp. 2790-2799). PMLR. <a href="#fnref5" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn6" class="footnote-item"><p>Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., &amp; Chen, W. (2022). LoRA: Low-Rank Adaptation of Large Language Models. In International Conference on Learning Representations. <a href="#fnref6" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn7" class="footnote-item"><p>Guo, D., Rush, A. M., &amp; Kim, Y. (2021). Parameter-Efficient Transfer Learning with Diff Pruning. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) (pp. 4884-4896). <a href="#fnref7" class="footnote-backref">↩︎</a></p>
</li>
<li id="fn8" class="footnote-item"><p>Xu, R., Luo, F., Zhang, Z., Tan, C., Chang, B., Huang, S., &amp; Huang, F. (2021). Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (pp. 9514-9528). <a href="#fnref8" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/2022/03/16/Unraveling-Implicit-Gradient-Regularization-in-Deep-Learning/" rel="prev" title="Unraveling Implicit Gradient Regularization in Deep Learning">
      <i class="fa fa-chevron-left"></i> Unraveling Implicit Gradient Regularization in Deep Learning
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/2022/11/28/SAM-Find-the-Approximate-Most-Important-Parameters-to-Fine-Tune/" rel="next" title="SAM -- Identifying the Most Significant Parameters for Fine-Tuning">
      SAM -- Identifying the Most Significant Parameters for Fine-Tuning <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#what-is-a-sparse-fine-tuned-model"><span class="nav-number">1.</span> <span class="nav-text"> What is a Sparse Fine-tuned Model?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#parameter-efficient-fine-tuning-models"><span class="nav-number">2.</span> <span class="nav-text"> Parameter-Efficient Fine-tuning Models</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#random-approaches"><span class="nav-number">2.1.</span> <span class="nav-text"> Random Approaches</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rule-based-approaches"><span class="nav-number">2.2.</span> <span class="nav-text"> Rule-Based Approaches</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#projection-based-approaches"><span class="nav-number">2.3.</span> <span class="nav-text"> Projection-Based Approaches</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#in-conclusion"><span class="nav-number">3.</span> <span class="nav-text"> In Conclusion</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Z.H. Fu"
      src="/blog/images/lion.png">
  <p class="site-author-name" itemprop="name">Z.H. Fu</p>
  <div class="site-description" itemprop="description">Z.H. Fu的博客，主要关注数学、力学、计算机相关内容</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">75</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
          
        <span class="site-state-item-count">57</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Z.H. Fu</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">137k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">8:19</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>




  




  
<script src="/blog/js/local-search.js"></script>













  

  
      
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css">


  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://maplewizard.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "http://fuzihaofzh.github.io/blog/2022/11/24/Sparse-Fine-tuned-Model-An-Unified-View-of-Parameter-Efficient-Models/";
    this.page.identifier = "2022/11/24/Sparse-Fine-tuned-Model-An-Unified-View-of-Parameter-Efficient-Models/";
    this.page.title = "Sparse Fine-tuned Model -- An Unified View of Parameter-Efficient Models";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://maplewizard.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
